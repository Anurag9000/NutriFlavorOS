# Python Dependencies for NutriFlavorOS
# GPU-Optimized Configuration for RTX 3050

# ============================================================================
# CRITICAL: GPU-Enabled PyTorch Installation
# ============================================================================
# The default torch/torchvision are CPU-only. For GPU support, install with:
# pip install torch==2.1.0+cu118 torchvision==0.16.0+cu118 --index-url https://download.pytorch.org/whl/cu118
#
# Or for CUDA 12.1:
# pip install torch==2.1.0+cu121 torchvision==0.16.0+cu121 --index-url https://download.pytorch.org/whl/cu121
# ============================================================================

# ML & Deep Learning (GPU-Compatible)
torch==2.1.0  # ⚠️ Install CUDA version manually (see above)
torchvision==0.16.0  # ⚠️ Install CUDA version manually (see above)
transformers==4.35.0  # ✅ GPU-compatible (uses PyTorch backend)

# Numerical Computing (CPU-based, but GPU alternatives available)
numpy==1.24.3  # ✅ CPU-based (use CuPy for GPU: pip install cupy-cuda11x)
scikit-learn==1.3.2  # ✅ CPU-based (use cuML for GPU acceleration)
pandas==2.1.3  # ✅ CPU-based (use cuDF for GPU acceleration)

# Core Framework (CPU-based, no GPU needed)
fastapi==0.104.1  # ✅ Web framework (CPU)
uvicorn[standard]==0.24.0  # ✅ ASGI server (CPU)
pydantic==2.5.0  # ✅ Data validation (CPU)
python-dotenv==1.0.0  # ✅ Environment variables (CPU)

# HTTP & API (CPU-based)
requests==2.31.0  # ✅ HTTP library (CPU)
httpx==0.25.1  # ✅ Async HTTP (CPU)

# Caching (Optional - for production)
redis==5.0.1  # ✅ In-memory cache (CPU)

# Image Processing (CPU-based, but GPU-compatible via PyTorch)
Pillow==10.1.0  # ✅ Image library (CPU, but torchvision handles GPU)

# Testing (CPU-based)
pytest==7.4.3  # ✅ Testing framework (CPU)
pytest-asyncio==0.21.1  # ✅ Async testing (CPU)

# Development (CPU-based)
black==23.11.0  # ✅ Code formatter (CPU)
flake8==6.1.0  # ✅ Linter (CPU)
mypy==1.7.0  # ✅ Type checker (CPU)

# ============================================================================
# GPU COMPATIBILITY SUMMARY
# ============================================================================
# ✅ FULLY GPU-COMPATIBLE (when CUDA PyTorch installed):
#    - torch, torchvision, transformers
#    - All ML models in backend/ml/ will use GPU automatically
#
# ✅ CPU-BASED (No GPU needed, works fine):
#    - fastapi, uvicorn, pydantic, requests, httpx, redis, Pillow
#    - pytest, black, flake8, mypy
#
# ⚠️ CPU-BASED (GPU alternatives available if needed):
#    - numpy → CuPy (pip install cupy-cuda11x)
#    - pandas → cuDF (pip install cudf-cu11 --extra-index-url=https://pypi.nvidia.com)
#    - scikit-learn → cuML (pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com)
#
# NOTE: For your ML models, numpy/pandas/scikit-learn on CPU is FINE because:
#    1. PyTorch handles all heavy GPU computation
#    2. numpy/pandas are only used for preprocessing (minimal overhead)
#    3. Adding RAPIDS (cuDF/cuML) is optional and only beneficial for
#       very large datasets (>1M rows)
# ============================================================================
